{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Inverse Problems and Regularisation\n",
    "\n",
    "In this section we consider inverse problems that can be posed as a system of linear equations\n",
    "\n",
    "$$\n",
    "Ku = f,\n",
    "$$\n",
    "\n",
    "with $K \\in \\mathbb{R}^{m\\times n}$ a given matrix and $f\\in \\mathbb{R}^{m}$ the data. The goal is to find a solution $u \\in \\mathbb{R}^n$ that (approximately) satisfies the equations.\n",
    "\n",
    "## Well-posedness\n",
    "The first questions we adress in detail are those of *existence*, *uniqueness* and *stability* of the solution.\n",
    "\n",
    "* If $m = n$ and $K$ has full rank, it is invertible and the solution is given by\n",
    "\n",
    "$$\n",
    "\\widetilde u = K^{-1}f.\n",
    "$$\n",
    "\n",
    "* If $m > n$ and $K$ has rank $n$, the system of equations may be *inconsistent* in which case a solution does not exist because $f$ is not in the range of $K$.\n",
    "\n",
    "* If $m < n$ and $K$ has rank $m$, we can always find a solution but it may not be unique because $K$ has a *null-space*.\n",
    "\n",
    "* If $K$ does not have maximal rank, the system of equations may be both inconsistent and $K$ can have a null-space.\n",
    "\n",
    "Stability in this context means that errors in the data do not get amplified too much. For now, we'll only consider stability in case the solution exists and is unique, in which case we have\n",
    "\n",
    "$$\n",
    "\\|\\widetilde u - \\widetilde u^{\\delta}\\| = \\|K^{-1}(f - f^{\\delta})\\| \\leq \\|K^{-1}\\| \\|f - f^{\\delta}\\|.\n",
    "$$\n",
    "\n",
    "Since $\\|f\\| = \\|K\\widetilde u\\| \\leq \\|K\\| \\|\\widetilde u\\|$, we can express the *relative error* as\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\widetilde u - \\widetilde u^{\\delta}\\|}{\\|\\widetilde u\\|} \\leq  \\|K\\|\\|K^{-1}\\| \\frac{\\|f - f^{\\delta}\\|}{\\|f\\|}.\n",
    "$$\n",
    "\n",
    "The quantity $\\kappa(K) = \\|K\\|\\|K^{-1}\\|$ is called the *condition number* of $K$. When $K$ is invertible, we have $\\kappa_2(K) = \\|K\\|_2\\|K^{-1}\\|_2 = \\sigma_1/\\sigma_n$.\n",
    "\n",
    "## Pseudo inverse and regularization\n",
    "If $m > n$, the system is inconsistent when $f$ is not in the range of $K$. If $K$ has full rank we can express it as\n",
    "\n",
    "$$\n",
    "K = U_n \\Sigma_n V_n^*.\n",
    "$$\n",
    "\n",
    "We can then attempt to solve a modified system of equations\n",
    "\n",
    "$$\n",
    "K u =  U_nU_n^* f,\n",
    "$$\n",
    "\n",
    "where $U_nU_n^* f$ projects $f$ onto the range of $K$. We find\n",
    "\n",
    "$$\n",
    "\\widetilde u = V_n\\Sigma_n^{-1}U_n^*f = K^\\dagger f.\n",
    "$$\n",
    "\n",
    "This coincides with the *least-squares* solution\n",
    "\n",
    "$$\n",
    "\\min_u \\|Ku - f\\|_2^2 .\n",
    "$$\n",
    "\n",
    "Indeed, by setting the gradient to zero, we find\n",
    "\n",
    "$$\n",
    "K^* K u  = K^* f,\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "\\widetilde u = (K^* K)^{-1}K^* f = K^{\\dagger}f.\n",
    "$$\n",
    "\n",
    "If, on the other hand $m < n$ and $K$ has full rank, a solution exists but is not unique. In this case, we can look for the smallest solution (i.e., one that does not have any contributions in the null-space of $K$).  This means we look for a solution that is spanned by the first $m$ columns of $V$\n",
    "\n",
    "$$\n",
    "K V_m z = f,\n",
    "$$\n",
    "\n",
    "with $\\widetilde u = V_m z$. We find that this solution is given by\n",
    "\n",
    "$$\n",
    "\\widetilde{u} = V_m\\Sigma_m^{-1}U_m^*f =  K^{\\dagger}f.\n",
    "$$\n",
    "\n",
    "Showing that this indeed yields the solution with the smallest norm is the subject of one of the assignments. The corresponding variational form is\n",
    "\n",
    "$$\n",
    "\\min_{u} \\|u\\|_2^2 \\quad \\text{such that} \\quad Ku = f.\n",
    "$$\n",
    "\n",
    "Dealing with such constraints will be the topic of a later lecture.\n",
    "\n",
    "If the matrix does not have full rank we may still employ the pseudo-inverse, which in general is defined as\n",
    "\n",
    "$$\n",
    "K^{\\dagger} = V_k\\Sigma_k^{-1}U_k^{*},\n",
    "$$\n",
    "\n",
    "where $k$ denotes the rank of the matrix.\n",
    "\n",
    "Note that the pseudo inverse allows us to define a unique solution, it is not necessarily stable as $\\|K\\|_2\\|K^{\\dagger}\\|_2 = \\sigma_1/\\sigma_k$ may still be large.\n",
    "\n",
    " To study this issue in more detail, express the solution as\n",
    " \n",
    "$$\n",
    "\\widetilde{u} = V_k\\Sigma_k^{-1}U_k^{*}f = \\sum_{i=1}^k \\frac{u_i^*f}{\\sigma_i}v_i.\n",
    "$$\n",
    "\n",
    "We note the component in $f$ corresponding to $v_i$ is amplified by $\\sigma_i^{-1}$. Thus if $f$ has (noise) components that correlate with $v_i$'s corresponding to very small singular values, these noise components get amplified. Generally, we do not expect problems if $|v_i^*f|$ decays faster with $i$ than the singular values $\\sigma_i$. This is called the \\*discrete Picard condition*.\n",
    "\n",
    "To stabilize the problem we can modify the pseudo inverse in several ways to avoid dividing by small singular values. One option is to simply ignore small singular values and choose a cut-off value and define the solution as\n",
    "\n",
    "$$\n",
    "\\widetilde u_{\\alpha} = V_{k}r_{\\alpha}(\\Sigma_{k}){U_{k}}^*f,\n",
    "$$\n",
    "\n",
    "where $r$ computes the regularized inverse:\n",
    "\n",
    "$$\n",
    "r_{\\alpha}(\\sigma) =\n",
    "\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\sigma^{-1} & \\text{if} \\quad \\sigma \\geq \\alpha \\\\\n",
    "0 & \\text{otherwise} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "This gives\n",
    "\n",
    "$$\n",
    "\\widetilde u_{\\alpha} = \\sum_{i=1}^{k_{\\alpha}} \\frac{u_i^*f}{\\sigma_i}v_i,\n",
    "$$\n",
    "\n",
    "where $k_{\\alpha}$ is chosen so that $\\sigma_i \\geq \\alpha$ for $i \\leq k_{\\alpha}$. This is called the *truncated singular value decomposition* (TSVD).\n",
    "\n",
    "Another option is to add small positive constant to shift the singular values away from zero\n",
    "\n",
    "$$\n",
    "r_{\\alpha}(\\sigma) = \\frac{s}{s^2 + \\alpha}.\n",
    "$$\n",
    "\n",
    "Stability of this type of modification follows by considering the largest singular value of the matrix $V_{k}r_{\\alpha}(\\Sigma_{k})U_{k}^{*}$, which can be made arbitrarily small by increasing $\\alpha$.\n",
    "\n",
    "The latter type of regularization is known as *Tikhonov regularization* and corresponds to the following variational formulation\n",
    "\n",
    "$$\n",
    "\\min_u \\|Ku - f\\|_2^2 + \\alpha \\|u\\|_2^2.\n",
    "$$\n",
    "\n",
    "Indeed, the solution is given by\n",
    "\n",
    "$$\n",
    "\\widetilde{u}_{\\alpha} = \\left(K^* K + \\alpha I\\right)^{-1}K^* f = V_k\\left(\\Sigma_k^2 + \\alpha I\\right)^{-1}\\Sigma_k {U_k}^*f,\n",
    "$$\n",
    "\n",
    "Note that $K^* K + \\alpha I$ has full rank whenever $\\alpha > 0$. Hence, the solution to this regularized problem exists and is unique.\n",
    "\n",
    "A final consideration when introducing such regularization is the *bias-variance tradeoff*. Here, we compare the regularized solution from noisy data $\\widetilde{u}_{\\alpha, \\delta} = K_{\\alpha}^\\dagger f^{\\delta}$ and the ideal solution $\\widetilde{u} = K^{\\dagger}f$:\n",
    "\n",
    "$$\n",
    "\\|\\widetilde u - \\widetilde u_{\\alpha, \\delta}\\| \\leq \\underbrace{\\|(K^\\dagger - K_{\\alpha}^\\dagger)f\\|}_{\\text{bias}} + \\underbrace{\\|K_{\\alpha}^\\dagger(f - f^{\\delta})\\|}_{\\text{variance}}.\n",
    "$$\n",
    "\n",
    "If $\\alpha \\downarrow 0$, the bias goes to zero, but possibly leads to a large variance. Large $\\alpha$ on the other hand reduces the variance but leads to a large bias. Ideally, the regularization parameter is chosen in such a way that the small singular values are stabilized and the large ones are hardly effected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
