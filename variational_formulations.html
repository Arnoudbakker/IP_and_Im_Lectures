

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>5. Variational formulations for inverse problems &#8212; 10 Lectures on Inverse Problems and Imaging</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/mystnb.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Numerical optimisation for inverse problems" href="numerical_optimisation.html" />
    <link rel="prev" title="4. A statistical perspective on inverse problems" href="statistical_perspective.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">10 Lectures on Inverse Problems and Imaging</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="what_is.html">
   1. What is an inverse problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discrete_ip_regularization.html">
   2. Discrete Inverse Problems and Regularisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ip_function_spaces.html">
   3. Linear inverse problems in function spaces
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="statistical_perspective.html">
   4. A statistical perspective on inverse problems
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. Variational formulations for inverse problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numerical_optimisation.html">
   6. Numerical optimisation for inverse problems
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="image_processing.html">
   1. Image processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tomography.html">
   2. Computed Tomography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wavefield_imaging.html">
   3. Wavefield Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="magnetic_resonance_imaging.html">
   4. Magnetic Resonance Imaging
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Preliminaries
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="linear_algebra.html">
   1. Linear algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="functional_analysis.html">
   2. Functional analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fourier_sampling.html">
   3. Fourier transform, distributions and sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="statistics.html">
   4. Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="variational_analysis.html">
   5. Variational analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convex_analysis.html">
   6. Convex analysis
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   1. Bibliography
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/variational_formulations.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/TristanvanLeeuwen/IP_and_Im_Lectures/edit/master/variational_formulations.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysis">
   5.1. Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#existence-and-uniqueness">
     5.1.1. Existence and uniqueness
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#well-posedness-of-regularised-least-squares-problems">
     5.1.2. Well-posedness of regularised least-squares problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples">
     5.1.3. Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#derivatives">
   5.2. Derivatives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-euler-lagrange-equations">
   5.3. The Euler-Lagrange equations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   5.4. Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#well-posedness-and-optimality-conditions">
     5.4.1. Well-posedness and optimality conditions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#well-posedness-of-the-rof-model">
     5.4.2. Well-posedness of the ROF model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deconvolution-using-the-l-1-norm">
     5.4.3. Deconvolution using the
     <span class="math notranslate nohighlight">
      \(L_1\)
     </span>
     norm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#frechet-derivatives">
     5.4.4. Fréchet derivatives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ell-2-denoising">
     5.4.5.
     <span class="math notranslate nohighlight">
      \(\ell_2\)
     </span>
     -denoising
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ell-1-denoising">
     5.4.6.
     <span class="math notranslate nohighlight">
      \(\ell_1\)
     </span>
     -denoising
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="variational-formulations-for-inverse-problems">
<h1><span class="section-number">5. </span>Variational formulations for inverse problems<a class="headerlink" href="#variational-formulations-for-inverse-problems" title="Permalink to this headline">¶</a></h1>
<p>So far, we have seen that inverse problems may generally be formulated as a variational problem</p>
<div class="math notranslate nohighlight" id="equation-variational">
<span class="eqno">(5.1)<a class="headerlink" href="#equation-variational" title="Permalink to this equation">¶</a></span>\[\min_{u\in\mathcal{U}} J(u),\]</div>
<p>where the <em>functional</em> <span class="math notranslate nohighlight">\(J : \mathcal{U} \rightarrow \mathbb{R}_{\infty}\)</span> consists of a <em>data-fidelity</em> and <em>regularisation</em> term. Here, <span class="math notranslate nohighlight">\(\mathbb{R}_{\infty} = \mathbb{R} \cup \{\infty\}\)</span> denotes the extended real line and <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> is a Banach space.</p>
<p>In this chapter we will discuss how to analyse the well-posedness of <a class="reference internal" href="#equation-variational">(5.1)</a> and lay out the connection between variational problems and PDEs through the <em>gradient flow</em>. The contents of this chapter were heavily inspired by the excellent <a class="reference external" href="https://mehrhardt.github.io/data/201803_lecture_notes_invprob.pdf">lecture notes from Matthias J. Ehrhardt and Lukas F. Lang</a></p>
<hr class="docutils" />
<p>Some notable examples are highlighted below.</p>
<div class="admonition-example-box-constraints admonition">
<p class="admonition-title">Example: <em>box constraints</em></p>
<p>Given a forward operator <span class="math notranslate nohighlight">\(K \in \mathbb{R}^{n\times n}\)</span> we can look for a solution in <span class="math notranslate nohighlight">\([0,1]^n\)</span> by solving a constrained minimisation problem</p>
<div class="math notranslate nohighlight">
\[\min_{u\in [0,1]^n} \|Ku - f^\delta\|_2^2.\]</div>
<p>However, this does not fall in the class <a class="reference internal" href="#equation-variational">(5.1)</a> since <span class="math notranslate nohighlight">\([0,1]^n\)</span> is not a vectorspace. To circumvent this we can alternatively express it as</p>
<div class="math notranslate nohighlight">
\[\min_{u\in \mathbb{R}^n} \|Ku - f^\delta\|_2^2 + \delta_{[0,1]^n}(u),\]</div>
<p>where <span class="math notranslate nohighlight">\(\delta_{\mathcal{C}}\)</span> denotes the <a class="reference external" href="https://en.wikipedia.org/wiki/Characteristic_function_(convex_analysis)">characteristic function</a> of the set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\delta_{\mathcal{C}}(u) = \begin{cases} 0 &amp; u \in \mathcal{C} \\ \infty &amp; \text{otherwise}\end{cases}.\end{split}\]</div>
<p>The corresponding functional <span class="math notranslate nohighlight">\(J\)</span> now takes values in the extended real line.</p>
</div>
<div class="admonition-example-sobolev-regularisation admonition">
<p class="admonition-title">Example: <em>Sobolev regularisation</em></p>
<p>Given a bounded linear operator <span class="math notranslate nohighlight">\(K:H^1(\Omega)\rightarrow L^2(\Omega)\)</span> and data <span class="math notranslate nohighlight">\(f^\delta\)</span>, we let <span class="math notranslate nohighlight">\(\nabla\)</span> denote the gradient</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku-f^{\delta}\|_{L^2(\Omega)}^2 +  \textstyle{\frac{\alpha}{2}}\|\nabla u\|_{L^2(\Omega)}^2.\]</div>
<p>This functional is well-defined for <span class="math notranslate nohighlight">\(u \in H^1(\Omega)\)</span>, with <span class="math notranslate nohighlight">\(H^1(\Omega)\)</span> denoting the <a class="reference external" href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev space</a> of functions <span class="math notranslate nohighlight">\(u\)</span> for which both <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(\nabla u\)</span> are square integrable. Thus, thus regularisation generally leads to smooth solutions.</p>
</div>
<div class="admonition-example-ell-1-regularization admonition">
<p class="admonition-title">Example: <em><span class="math notranslate nohighlight">\(\ell_1\)</span>-regularization</em></p>
<p>Consider a forward operator <span class="math notranslate nohighlight">\(K:\ell_1 \rightarrow \ell_2\)</span> and let</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku - f^\delta\|_{\ell_2}^2 + \alpha \|u\|_{\ell_1}.\]</div>
<p>Such regularisation is often used to promote <em>sparse</em> solutions.</p>
</div>
<div class="admonition-example-total-variation-regularisation admonition">
<p class="admonition-title">Example: <em>Total Variation regularisation</em></p>
<p>Consider recovering a function <span class="math notranslate nohighlight">\(u: [0,1] \rightarrow \mathbb{R}\)</span> from noisy measurements <span class="math notranslate nohighlight">\(f^\delta = Ku + e\)</span>. A popular choice in imaging applications is to put an <span class="math notranslate nohighlight">\(L^1\)</span>-norm on the derivative. For <span class="math notranslate nohighlight">\(u\in W^{1,1}([0,1])\)</span> this yields</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku-f^{\delta}\|_{L^2([0,1])}^2 + \alpha \|u'\|_{L^1([0,1])}.\]</div>
<p>This can be generalised to include certain non-smooth functions by introducing the space of functions of <a class="reference external" href="https://en.wikipedia.org/wiki/Bounded_variation">bounded variation</a>, denoted by <span class="math notranslate nohighlight">\(BV([0,1])\)</span>. Functions in <span class="math notranslate nohighlight">\(BV([0,1])\)</span> are characterised as having a finite <a class="reference external" href="https://en.wikipedia.org/wiki/Total_variation">Total Variation</a></p>
<div class="math notranslate nohighlight">
\[TV(u) = \sup_{\phi \in D([0,1],\mathbb{R})} \int_0^1 u(x)\phi'(x)\mathrm{d}x,\]</div>
<p>where <span class="math notranslate nohighlight">\(D([0,1],\mathbb{R})\)</span> is the space of smooth test functions with <span class="math notranslate nohighlight">\(\|\phi\|_{L^\infty([0,1])}\leq 1\)</span>. This space is much larger than <span class="math notranslate nohighlight">\(H^{1,1}([0,1])\)</span> as it contains certain discontinuous functions (such as the Heaveside stepfunction) and smaller than <span class="math notranslate nohighlight">\(L^1(0,1)\)</span> (which also contains less regular functions). For functions in <span class="math notranslate nohighlight">\(H^{1,1}\)</span> we have <span class="math notranslate nohighlight">\(TV(u) = \|u'\|_{L^1([0,1])}\)</span>.</p>
</div>
<div class="section" id="analysis">
<h2><span class="section-number">5.1. </span>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="existence-and-uniqueness">
<h3><span class="section-number">5.1.1. </span>Existence and uniqueness<a class="headerlink" href="#existence-and-uniqueness" title="Permalink to this headline">¶</a></h3>
<p>To establish existence of minimisers, we first need a few definitions.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Minimisers</em></p>
<p>We say that <span class="math notranslate nohighlight">\(\widetilde{u} \in \mathcal{U}\)</span> solves <a class="reference internal" href="#equation-variational">(5.1)</a> iff <span class="math notranslate nohighlight">\(J(\widetilde{u}) &lt; \infty\)</span> and <span class="math notranslate nohighlight">\(J(\widetilde{u}) \leq J(u)\)</span> for all <span class="math notranslate nohighlight">\(u \in \mathcal{U}\)</span>.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Proper functionals</em></p>
<p>A functional <span class="math notranslate nohighlight">\(J\)</span> is called proper if its effective domain <span class="math notranslate nohighlight">\(\text{dom}(J) = \{u\in\mathcal{U} \, | \, J(u) &lt; \infty\}\)</span> is not empty.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Bounded from below</em></p>
<p>A functional <span class="math notranslate nohighlight">\(J\)</span> is bounded from below if there exists a constant <span class="math notranslate nohighlight">\(C &gt; -\infty\)</span> such that <span class="math notranslate nohighlight">\(\forall u\in \mathcal{U}\)</span> we have <span class="math notranslate nohighlight">\(J(u) \geq C\)</span>.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Coercive functionals</em></p>
<p>A functional <span class="math notranslate nohighlight">\(J\)</span> is called coercive if for all <span class="math notranslate nohighlight">\(\{u_j\}_{j\in\mathbb{N}}\)</span> with <span class="math notranslate nohighlight">\(\|u_j\|_{\mathcal{U}}\rightarrow \infty\)</span> we have <span class="math notranslate nohighlight">\(J(u_j) \rightarrow\infty\)</span>.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Lower semi-continuity</em></p>
<p>A functional <span class="math notranslate nohighlight">\(J\)</span> is lower semi-continuous at <span class="math notranslate nohighlight">\(u\)</span> if for every <span class="math notranslate nohighlight">\(a &lt; J(u)\)</span> there exists a neighbourhood <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> of <span class="math notranslate nohighlight">\(u\)</span> such that <span class="math notranslate nohighlight">\(a &lt; J(v)\)</span> for all <span class="math notranslate nohighlight">\(v \in \mathcal{X}\)</span>.</p>
<p>Note that the term <em>neighbourhood</em> implies an underlying topology, which may be different (in particular, weaker) than the one induced by the norm on <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>.</p>
</div>
<p>With these, we can establish existence.</p>
<div class="important admonition">
<p class="admonition-title">Theorem: <em>Fundamental theorem of optimisation</em></p>
<p>Let <span class="math notranslate nohighlight">\(J : \mathcal{U} \rightarrow \mathbb{R}\)</span> be proper, coercive, bounded from below and lower semi-continuous. Then <span class="math notranslate nohighlight">\(J\)</span> has a minimiser.</p>
</div>
<div class="admonition-examples-existence-of-minimisers-in-mathbb-r admonition">
<p class="admonition-title">Examples: <em>existence of minimisers in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span></em></p>
<p>Consider the following functions <span class="math notranslate nohighlight">\(J:\mathbb{R}\rightarrow \mathbb{R}\)</span> (cf. <a class="reference internal" href="#functionals"><span class="std std-numref">Fig. 5.1</span></a>):</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J_1(x) = x^3,\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(J_2(x) = e^x,\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(J_3(x) = \begin{cases}x^2 &amp; x &lt; 0 \\ 1 + x &amp; x \geq 0\end{cases}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(J_4(x) = \begin{cases}x^2 &amp; x \leq 0 \\ 1 + x &amp; x &gt; 0\end{cases}\)</span></p></li>
</ul>
<p>We see that <span class="math notranslate nohighlight">\(J_1\)</span> is not bounded from below; <span class="math notranslate nohighlight">\(J_2\)</span> is not coercive, <span class="math notranslate nohighlight">\(J_3\)</span> is not l.s.c while <span class="math notranslate nohighlight">\(J_4\)</span> is.</p>
<div class="figure align-default" id="functionals" style="width: 600px">
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_1_0.png" src="_images/variational_formulations_1_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 5.1 </span><span class="caption-text">Examples of various functions.</span><a class="headerlink" href="#functionals" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="c1"># grid</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">,</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">),</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">30</span><span class="p">:],</span><span class="n">x</span><span class="p">[</span><span class="mi">30</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;bo&#39;</span><span class="p">,</span><span class="n">fillstyle</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;bo&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">x</span><span class="p">[</span><span class="mi">30</span><span class="p">:],</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">30</span><span class="p">:],</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;bo&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;bo&#39;</span><span class="p">,</span><span class="n">fillstyle</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;functionals&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_1_1.png" src="_images/variational_formulations_1_1.png" />
</div>
</div>
<div class="important admonition">
<p class="admonition-title">Theorem: <em>Uniqueness of minimisers</em></p>
<p>Let <span class="math notranslate nohighlight">\(J\)</span> have at least one minimiser and be <a class="reference external" href="https://en.wikipedia.org/wiki/Convex_function">strictly convex</a> then the minimiser is unique.</p>
</div>
</div>
<div class="section" id="well-posedness-of-regularised-least-squares-problems">
<h3><span class="section-number">5.1.2. </span>Well-posedness of regularised least-squares problems<a class="headerlink" href="#well-posedness-of-regularised-least-squares-problems" title="Permalink to this headline">¶</a></h3>
<p>In this section we focus in particular on variational problems of the form</p>
<div class="math notranslate nohighlight" id="equation-variational-r">
<span class="eqno">(5.2)<a class="headerlink" href="#equation-variational-r" title="Permalink to this equation">¶</a></span>\[\textstyle{\frac{1}{2}}\|Ku - f^\delta\|_{\mathcal{F}}^2 + \alpha R(u),\]</div>
<p>with <span class="math notranslate nohighlight">\(K: \mathcal{U} \rightarrow \mathcal{F}\)</span> a bounded linear operator and <span class="math notranslate nohighlight">\(R : \mathcal{U} \rightarrow \mathbb{R}_{\infty}\)</span> is proper and l.s.c. (with respect to an appropriate topology).</p>
<p>We can think of this as defining a (possibly non-linear) regularisation scheme <span class="math notranslate nohighlight">\(\widetilde{u}_{\alpha,\delta} = K_{\alpha}^\dagger(f^\delta)\)</span> that generalises the pseudo-inverse approach discussed earlier. Note that the notation <span class="math notranslate nohighlight">\(K_{\alpha}^\dagger\)</span> is used very loosely to indicate a mapping from <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> to <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> that is supposed to approximate the inverse of <span class="math notranslate nohighlight">\(K\)</span> in some fashion. In general, this will be a non-linear mapping.</p>
<div class="admonition-theorem-existence-and-uniqueness-of-regularised-least-squares-solutions admonition">
<p class="admonition-title">Theorem: <em>Existence and uniqueness of regularised least-squares solutions</em></p>
<p>Let <span class="math notranslate nohighlight">\(K\)</span> be injective or <span class="math notranslate nohighlight">\(J\)</span> be strictly convex, then the variational problem <a class="reference internal" href="#equation-variational-r">(5.2)</a> has a unique minimiser.</p>
</div>
<div class="admonition-theorem-stability-of-regularised-least-squares-solutions admonition">
<p class="admonition-title">Theorem: <em>Stability of regularised least-squares solutions</em></p>
<p>…</p>
</div>
</div>
<div class="section" id="examples">
<h3><span class="section-number">5.1.3. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<div class="admonition-example-tikhonov-regularisation-in-mathbb-r-n admonition">
<p class="admonition-title">Example: <em>Tikhonov regularisation in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span></em></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku - f^\delta\|_2^2 + \textstyle{\frac{\alpha}{2}}\|u\|_2^2.\]</div>
<p>Here, <span class="math notranslate nohighlight">\(J\)</span> is obviously bounded from below and proper. To show that <span class="math notranslate nohighlight">\(J\)</span> is coercive, we note that <span class="math notranslate nohighlight">\(J(u) \geq \textstyle{\frac{\alpha}{2}}\|u\|_2^2\)</span> and hence that <span class="math notranslate nohighlight">\(J(u) \rightarrow \infty\)</span> as <span class="math notranslate nohighlight">\(\|u\|_2 \rightarrow \infty\)</span>. To show that <span class="math notranslate nohighlight">\(J\)</span> is l.s.c., we will show that <span class="math notranslate nohighlight">\(J\)</span> is continuous since this implies l.s.c. First note that</p>
<div class="math notranslate nohighlight">
\[J(u + d) = J(u) + \textstyle{\frac{1}{2}}\|Kd\|_2^2 - \langle Kd,Ku - f^\delta \rangle + \textstyle{\frac{\alpha}{2}}\|d\|_2^2 + \alpha \langle d,u\rangle,\]</div>
<p>from which we can bound</p>
<div class="math notranslate nohighlight">
\[|J(v) - J(u)| \leq \textstyle{\frac{1}{2}}\|Kd\|_2^2 + \|Kd\|_2 \|Ku - f^\delta\|_2 + \alpha \|d\|_2 \|u\|_2 + \textstyle{\frac{\alpha}{2}}\|d\|_2^2 \leq A \|d\|_2^2 + B \|d\|_2.\]</div>
<p>Now, for every <span class="math notranslate nohighlight">\(\epsilon\)</span> we can pick a <span class="math notranslate nohighlight">\(\delta\)</span> such that <span class="math notranslate nohighlight">\(\|u-v\|_2 &lt; \delta\)</span> implies that <span class="math notranslate nohighlight">\(|J(v) - J(u)| &lt; \epsilon\)</span>.</p>
<p>Finally, we can show that <span class="math notranslate nohighlight">\(J\)</span> is <em>strongly convex</em> with constant <span class="math notranslate nohighlight">\(\alpha\)</span> by showing that <span class="math notranslate nohighlight">\(J(u) - \textstyle{\frac{\alpha}{2}}\|u\|_2^2\)</span> is convex. The fact that <span class="math notranslate nohighlight">\(\|Ku - f^\delta\|_2^2\)</span> is convex follows easily from the triangle inequality and the fact that the function <span class="math notranslate nohighlight">\(\cdot^2\)</span> is convex.</p>
</div>
<div class="admonition-example-ell-1-regularisation admonition">
<p class="admonition-title">Example: <em><span class="math notranslate nohighlight">\(\ell_1-regularisation\)</span></em></p>
<p>Consider</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku - f^\delta\|_{\ell_2}^2 + \alpha \|u\|_{\ell_1},\]</div>
<p>with <span class="math notranslate nohighlight">\(K : \ell_2 \rightarrow \ell_2\)</span> a bounded operator. Again, we can easily see that <span class="math notranslate nohighlight">\(J\)</span> is bounded from below.</p>
<p>Note that the regularised solution is determined for all <span class="math notranslate nohighlight">\(f \in \ell_2\)</span>, regardless of the Picard condition.</p>
</div>
<div class="admonition-example-sobolev-regularisation admonition">
<p class="admonition-title">Example: <em>Sobolev regularisation</em></p>
<p>Consider</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku - f^\delta\|_{L^2(\Omega)}^2 + \textstyle{\frac{\alpha}{2}}\|\nabla u\|_{L^2(\Omega)}^2.\]</div>
</div>
<div class="admonition-example-total-variation-regularisation admonition">
<p class="admonition-title">Example: <em>Total variation regularisation</em></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[J(u) = \textstyle{\frac{1}{2}}\|Ku - f^\delta\|_{L^2(\Omega)}^2 + \alpha TV(u).\]</div>
<ul class="simple">
<li><p>existence, uniqueness, stability</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="derivatives">
<h2><span class="section-number">5.2. </span>Derivatives<a class="headerlink" href="#derivatives" title="Permalink to this headline">¶</a></h2>
<p>Having established well-posedness of <a class="reference internal" href="#equation-variational">(5.1)</a>, we now focus our attention to characterising solutions through the first-order optimality conditions.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Fréchet derivative</em></p>
<p>We call a functional <span class="math notranslate nohighlight">\(J:\mathcal{U}\rightarrow \mathbb{R}\)</span> Fréchet differentiable (at <span class="math notranslate nohighlight">\(u\)</span>) if
there exists a linear operator <span class="math notranslate nohighlight">\(D\)</span> such that</p>
<div class="math notranslate nohighlight" id="equation-frechet">
<span class="eqno">(5.3)<a class="headerlink" href="#equation-frechet" title="Permalink to this equation">¶</a></span>\[\lim_{h\rightarrow 0} \frac{|J(u+h) - J(u) - Dh|}{\|h\|_{\mathcal{U}}} = 0.\]</div>
<p>If this operator exists for all <span class="math notranslate nohighlight">\(u \in\mathcal{U}\)</span> we call <span class="math notranslate nohighlight">\(J\)</span> Fréchet differentiable and denote its Fréchet derivative by <span class="math notranslate nohighlight">\(J': \mathcal{U} \rightarrow \mathcal{U}^*\)</span>. Here, <span class="math notranslate nohighlight">\(\mathcal{U}^*\)</span> denotes the <a class="reference external" href="https://en.wikipedia.org/wiki/Dual_space">dual space</a> of <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> which consists of bounded linear functionals on <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>.</p>
</div>
<p>With this more general notion of differentiation we can pose the first-order optimality conditions.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>First-order optimality conditions</em></p>
<div class="math notranslate nohighlight" id="equation-local-minimum">
<span class="eqno">(5.4)<a class="headerlink" href="#equation-local-minimum" title="Permalink to this equation">¶</a></span>\[\langle J'(u), v - u\rangle \geq 0.\]</div>
</div>
<p>We need to be careful here, as some important cases <span class="math notranslate nohighlight">\(J\)</span> may fail to be Fréchet differentiable at the solution.</p>
<hr class="docutils" />
<p>A well-known method for solving <a class="reference internal" href="#equation-variational">(5.1)</a> is the <em>Landweber</em> iteration</p>
<div class="math notranslate nohighlight">
\[u_{k+1} = u_k - \lambda J'(u_k),\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> denotes the stepsize. Under certain conditions on <span class="math notranslate nohighlight">\(J'(u)\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span> one can show that this converges to a stationary point <span class="math notranslate nohighlight">\(u_{*}\)</span> for which <span class="math notranslate nohighlight">\(J'(u_*) = 0\)</span>. Obviously, this method only applies when <span class="math notranslate nohighlight">\(J'(u)\)</span> is well-defined everywhere along the solution path.</p>
<hr class="docutils" />
<p>It turns out that we can make an important distinction between <em>smooth</em> and <em>convex</em> (non-smooth) functionals.
We will explore optimality conditions and algorithms for these two classes in more detail in a later chapter.</p>
</div>
<div class="section" id="the-euler-lagrange-equations">
<h2><span class="section-number">5.3. </span>The Euler-Lagrange equations<a class="headerlink" href="#the-euler-lagrange-equations" title="Permalink to this headline">¶</a></h2>
<p>An alternative viewpoint on optimality is provided by the Euler-lagrange equations, which establishes the link between certain problems of the form <a class="reference internal" href="#equation-variational">(5.1)</a> and PDEs. In particular, we focus in this section on problems of the form</p>
<div class="math notranslate nohighlight">
\[\min_{u\in\mathcal{U}} \textstyle{\frac{1}{2}} \|u - f^\delta\|_{L^2(\Omega)} + \alpha R(\nabla u).\]</div>
<p>Such problems occur for example in image-denoising applications. We will see later that such problems also occur as subproblems when solving more general problems of the form <a class="reference internal" href="#equation-variational-r">(5.2)</a>.</p>
<div class="important admonition">
<p class="admonition-title">Definition: Euler-Lagrange equations</p>
<p>The first-order optimality condition for <span class="math notranslate nohighlight">\(u\in\mathcal{U}\)</span> to be a solution to <a class="reference internal" href="#equation-variational">(5.1)</a> is</p>
<div class="math notranslate nohighlight">
\[\left.\frac{\mathrm{d}}{\mathrm{d}t} J(u + t\phi)\right|_{t=0} = 0 \quad \forall \phi \in C_c^{\infty},\]</div>
<p>where <span class="math notranslate nohighlight">\(..\)</span></p>
</div>
<div class="admonition-example-the-heat-equation admonition">
<p class="admonition-title">Example: <em>The heat equation</em></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[R(u) = \|\nabla u\|_{L^2(\Omega)}^2.\]</div>
<p>The corresponding diffusion equation is given by</p>
<div class="math notranslate nohighlight">
\[\partial_t u + u - \alpha\nabla^2 u = f^\delta.\]</div>
<ul class="simple">
<li><p>definition of underlying spaces, boundary conditions.</p></li>
</ul>
<p>A forward Euler discretisation of the PDE leads to</p>
<div class="math notranslate nohighlight">
\[u_{k+1} = u_k - \Delta t \left(f^\delta - u + \alpha \nabla^2 u\right),\]</div>
<p>which is in fact a Landweber iteration applied to the corresponding objective.</p>
<div class="figure align-default" id="linear-diffusion" style="width: 600px">
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_3_0.png" src="_images/variational_formulations_3_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 5.2 </span><span class="caption-text">Example of denoising with linear diffusion.</span><a class="headerlink" href="#linear-diffusion" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">skimage.util</span> <span class="kn">import</span> <span class="n">random_noise</span>
<span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="kn">import</span> <span class="n">resize</span>

<span class="c1"># parameters</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">niter</span> <span class="o">=</span> <span class="mi">1001</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">0</span><span class="o">*</span><span class="n">s</span>

<span class="c1"># diffusion operator</span>
<span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">coeff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">0</span><span class="o">*</span><span class="n">s</span><span class="p">):</span>
    <span class="n">ue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">)</span> <span class="c1"># padd edges to get array of size n+2 x n+2</span>

    <span class="c1"># diffusion coefficient (central differences)</span>
    <span class="n">grad_norm</span> <span class="o">=</span> <span class="p">((</span><span class="n">ue</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ue</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">((</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">coeff</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">)</span>

    <span class="c1"># diffusion term (combination of forward and backward differences)</span>
    <span class="n">uxx</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">uyy</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">,]))</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">uxx</span> <span class="o">+</span> <span class="n">uyy</span>

<span class="c1"># noisy image</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">(),(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">random_noise</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">var</span><span class="o">=</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># solve evolution equation</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">niter</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">dt</span><span class="o">*</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="n">L</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">coeff</span><span class="p">))</span> <span class="o">+</span> <span class="n">dt</span><span class="o">*</span><span class="n">f_delta</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f_delta</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Noisy image&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Result&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;linear_diffusion&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_3_1.png" src="_images/variational_formulations_3_1.png" />
</div>
</div>
<div class="admonition-example-non-linear-diffusion admonition">
<p class="admonition-title">Example: <em>Non-linear diffusion</em></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[R(u) = \int_{\Omega} r\left(\|\nabla u(x)\|^2\right) \mathrm{d}x.\]</div>
<p>A popular choice for <span class="math notranslate nohighlight">\(r = \log(1 + s/\epsilon^2)\)</span>, which leads to the Perona-Malik diffusion equation:</p>
<div class="math notranslate nohighlight">
\[\partial_t u + u - \alpha\nabla \cdot \left(\frac{\nabla u}{1 + \epsilon^{-2}\|\nabla u\|_2^2}\right) = f^\delta.\]</div>
<p>We can interpret intuitively why this would preserve edges by looking at the diffusion coefficient. Wherever <span class="math notranslate nohighlight">\(\|\nabla u\| \ll \epsilon\)</span> we have linear diffusion, if <span class="math notranslate nohighlight">\(\|\nabla u\| \gg \epsilon\)</span>, we hardly have any diffusion. This intuition if confirmed by consider the penalty <span class="math notranslate nohighlight">\(r(s)\)</span>, which for small <span class="math notranslate nohighlight">\(s\)</span> behaves like <span class="math notranslate nohighlight">\(s^2\)</span> but then flattens out and will thus not increasingly penalise larger gradients.</p>
<div class="figure align-default" id="perona-malik" style="width: 600px">
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_5_0.png" src="_images/variational_formulations_5_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 5.3 </span><span class="caption-text">Example of denoising with Perona-Malik regularisation.</span><a class="headerlink" href="#perona-malik" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">skimage.util</span> <span class="kn">import</span> <span class="n">random_noise</span>
<span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="kn">import</span> <span class="n">resize</span>

<span class="c1"># parameters</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">niter</span> <span class="o">=</span> <span class="mi">1001</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mf">1e6</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>

<span class="c1"># diffusion operator</span>
<span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">coeff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">ue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">)</span> <span class="c1"># padd edges to get array of size n+2 x n+2</span>

    <span class="c1"># diffusion coefficient (central differences)</span>
    <span class="n">grad_norm</span> <span class="o">=</span> <span class="p">((</span><span class="n">ue</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ue</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">((</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">coeff</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">)</span>

    <span class="c1"># diffusion term (combination of forward and backward differences)</span>
    <span class="n">uxx</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">uyy</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ue</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">,]))</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">uxx</span> <span class="o">+</span> <span class="n">uyy</span>

<span class="c1"># noisy image</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">(),(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">random_noise</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">var</span><span class="o">=</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># solve evolution equation</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">niter</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">dt</span><span class="o">*</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="n">L</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">coeff</span><span class="p">))</span> <span class="o">+</span> <span class="n">dt</span><span class="o">*</span><span class="n">f_delta</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f_delta</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Noisy image&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Result&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;perona_malik&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_5_1.png" src="_images/variational_formulations_5_1.png" />
</div>
</div>
<div class="admonition-example-total-variation admonition">
<p class="admonition-title">Example: <em>Total variation</em></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[R(u) = ...\]</div>
</div>
</div>
<div class="section" id="exercises">
<h2><span class="section-number">5.4. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<div class="section" id="well-posedness-and-optimality-conditions">
<h3><span class="section-number">5.4.1. </span>Well-posedness and optimality conditions<a class="headerlink" href="#well-posedness-and-optimality-conditions" title="Permalink to this headline">¶</a></h3>
<p>The following functionals are given (for <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span> and <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{2 \times 2}\)</span> an invertible matrix):</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J_1: \mathbb{R} \rightarrow \mathbb{R}, u \mapsto \frac{1}2(u-f)^2 + \alpha|u|\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(J_2: \mathbb{R} \rightarrow \mathbb{R}, u \mapsto |u-f| + \alpha u^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(J_3: \mathbb{R}^2 \rightarrow \mathbb{R}, u \mapsto \frac{1}2\Vert A u - f\Vert_{\ell^2}^2  + \alpha \Vert u \Vert_{\ell^2}\)</span></p></li>
</ul>
<p>For the optimisation problems <span class="math notranslate nohighlight">\(J_i(u) \rightarrow \min_u\)</span> perform the following analysis:</p>
<p><strong>Proof</strong>, that a minimum exists (use the fundamental theorem of optimisation) and <strong>proof</strong> that it is unique.</p>
<p><strong>Compute</strong> the optimality conditions and thereof (using cases) a solution formula dependent on <span class="math notranslate nohighlight">\(f\)</span>. It holds for <span class="math notranslate nohighlight">\(p\in\partial\left\|u\right\|_{\ell^2}\)</span> that
<span class="math notranslate nohighlight">\($p = \frac{u}{\left\|u\right\|_{\ell^2}} \text{ for } \; u\neq 0 \text{, and }\)</span>$
<span class="math notranslate nohighlight">\($p \in \mathrm{B}_1(0) \quad \text{ for } \; u = 0\, \qquad\)</span>$
where <span class="math notranslate nohighlight">\(\mathrm{B}_1(0)\)</span> denotes the unit ball around <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Hint: Remark, that for <span class="math notranslate nohighlight">\(J_3\)</span> no explicit solution formula can be given. Hence, use the following substitution
<span class="math notranslate nohighlight">\(c:=\frac{\alpha}{\left\|u\right\|_{\ell^2}}\)</span> and provide a solution formula dependent on <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(f\)</span>.</p>
</div>
<div class="section" id="well-posedness-of-the-rof-model">
<h3><span class="section-number">5.4.2. </span>Well-posedness of the ROF model<a class="headerlink" href="#well-posedness-of-the-rof-model" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>For existence of a solution, verify why the TV functional is lower semi-continuous in the corresponding topology.</p></li>
<li><p>Does the Rudin-Osher-Fatemi model have a unique minimizer? Why or why not?</p></li>
</ul>
</div>
<div class="section" id="deconvolution-using-the-l-1-norm">
<h3><span class="section-number">5.4.3. </span>Deconvolution using the <span class="math notranslate nohighlight">\(L_1\)</span> norm<a class="headerlink" href="#deconvolution-using-the-l-1-norm" title="Permalink to this headline">¶</a></h3>
<p>For given data <span class="math notranslate nohighlight">\(f\)</span> and a convolution kernel <span class="math notranslate nohighlight">\(k\)</span> we study the following regularized variational method:</p>
<div class="math notranslate nohighlight">
\[
\left\| k \ast u - f \right\|_{L^2(\Omega)}^2 \:+\: \alpha \: \int_\Omega | (\mathcal{F}u)(w) | \: dw \: \rightarrow \: \min_{u}
\]</div>
<p>where <span class="math notranslate nohighlight">\((\mathcal{F}u)(w)\)</span> denotes the Fourier transform of <span class="math notranslate nohighlight">\(u\)</span> at wave number <span class="math notranslate nohighlight">\(w\)</span>. Similar to the lecture, find an explicit representation of the solution of the problem using the <a class="reference external" href="https://en.wikipedia.org/wiki/Convolution_theorem">convolution theorem</a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Plancherel_theorem">Plancherel theorem</a>. For simplicity you can assume that everything is real valued.</p>
<p>Hint: The derivative of the absolute value function is multivalued (you need cases).</p>
</div>
<div class="section" id="frechet-derivatives">
<h3><span class="section-number">5.4.4. </span>Fréchet derivatives<a class="headerlink" href="#frechet-derivatives" title="Permalink to this headline">¶</a></h3>
<p>Let <span class="math notranslate nohighlight">\(\Omega \subset \mathbb{R}^2\)</span> and <span class="math notranslate nohighlight">\(\Sigma \subset \mathbb{R}^2\)</span>. Compute the Fréchet derivatives of the following functionals:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(u) = \frac{1}{2} \left\| \nabla u \right\|_{L^2(\Omega)}^2\)</span> where <span class="math notranslate nohighlight">\(u \in W^{1,2}(\Omega)\)</span>.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title">Answer</p>
<p>We have <span class="math notranslate nohighlight">\(J(u + h) = \textstyle{\frac{1}{2}}\|\nabla u + \nabla h\|^2 = \textstyle{\frac{1}{2}}\|\nabla u\|^2 +  \int_{\Omega}\nabla u(x) \cdot \nabla h(x) \mathrm{d}x + \textstyle{\frac{1}{2}}\|\nabla h\|^2\)</span>. This suggests that <span class="math notranslate nohighlight">\(DJ(u) : U \rightarrow \mathbb{R}\)</span> can be defined as <span class="math notranslate nohighlight">\(DJ(u)v = \int_{\Omega}\nabla u(x) \cdot \nabla v(x) \mathrm{d}x\)</span>. Indeed, we can verify that</p>
<div class="math notranslate nohighlight">
\[
\lim_{\|h\|\rightarrow 0} \frac{\left| \int_{\Omega}\nabla h (x) \cdot \nabla h(x)\mathrm{d}x \right|}{\sqrt{\int_{\Omega} |h(x)|^2 + |\nabla h(x) \cdot \nabla h(x) | \mathrm{d}x}} = 0.
\]</div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(u) = \frac{1}{2} \left\| Ku-f \right\|_{L^2(\Sigma)}^2\)</span> where <span class="math notranslate nohighlight">\(K: L^2(\Omega) \rightarrow L^2(\Sigma)\)</span> is a compact linear operator, <span class="math notranslate nohighlight">\(u : \Omega \rightarrow \mathbb{R}\)</span> and <span class="math notranslate nohighlight">\(f : \Sigma \rightarrow \mathbb{R}\)</span>.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title">Answer</p>
<p>We have <span class="math notranslate nohighlight">\(J(u+h) = J(u) + \langle Ku - f, Kv \rangle + \textstyle{\frac{1}{2}}\|Kv\|^2.\)</span> This suggests letting <span class="math notranslate nohighlight">\(DJ(u)v = \langle Ku - f, Kv\rangle = \langle K^*(Ku - f), v\rangle\)</span>. Indeed</p>
<div class="math notranslate nohighlight">
\[
\lim_{\|h\|\rightarrow 0}\frac{\|Kh\|^2_{L^2}}{\|h\|_{L^2}} = 0,
\]</div>
<p>because <span class="math notranslate nohighlight">\(K\)</span> is bounded.</p>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(\mathbf{v}) = \frac{1}{2} \left\| \partial_t f + \nabla\cdot(f \mathbf{v}) \right\|_{L^2(\Omega \times [0,T])}^2\)</span>
where <span class="math notranslate nohighlight">\(f\)</span> here represents an image sequence, i.e. <span class="math notranslate nohighlight">\(f: \Omega \times [0,T] \rightarrow \mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> denotes a desired vector field, i.e. <span class="math notranslate nohighlight">\(\mathbf{v}: \Omega \times [0,T] \rightarrow \mathbb{R}^2\)</span>.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Here, we have <span class="math notranslate nohighlight">\(J(\mathbf{v} + \mathbf{h}) = J(\mathbf{v}) + \langle \partial_t f + \nabla \cdot (f\mathbf{v}),  \nabla \cdot (f\mathbf{h})\rangle + \textstyle{\frac{1}{2}}\|\nabla \cdot (f\mathbf{h})\|^2\)</span>, suggesting</p>
<div class="math notranslate nohighlight">
\[
DJ(\mathbf{v})\mathbf{h} = \int_0^T \int_{\Omega} \left(\partial_t f(x,t) + \nabla \cdot (f(x,t)\mathbf{v}(x,t))\right)\left(\nabla \cdot (f(x,t)\mathbf{v}(x,t))\right) \mathrm{d}t\mathrm{d}x.
\]</div>
</div>
</div>
<div class="section" id="ell-2-denoising">
<h3><span class="section-number">5.4.5. </span><span class="math notranslate nohighlight">\(\ell_2\)</span>-denoising<a class="headerlink" href="#ell-2-denoising" title="Permalink to this headline">¶</a></h3>
<p>Consider the Tikhonov functional for denoising (in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>):</p>
<div class="math notranslate nohighlight">
\[
\min\limits_u\textstyle{\frac{1}{2}}\left\|u-f\right\|_2^2 + \frac{\alpha}{2}\left\|u\right\|_2^2.
\]</div>
<ul class="simple">
<li><p>Give the solution of this variational problem explicitly.</p></li>
<li><p>Generate in Python a random 1x128 vector with 5 non-zero coefficients (entries) and add aussian noise with standard deviation <span class="math notranslate nohighlight">\(\sigma = 0.05\)</span> (see example below)</p></li>
<li><p>Denoise the vector by solving the variational problem. What happens for different regularisation parameters <span class="math notranslate nohighlight">\(\alpha = \left\{0.01, 0.05, 0.1, 0.2\right\}\)</span>?. Consider in particular <span class="math notranslate nohighlight">\(\alpha=0.1\)</span>. <em>Is the solution sparse?</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># generate spiky signal with random amplitudes</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># generate noisy signal</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x1268073d0&gt;]
</pre></div>
</div>
<img alt="_images/variational_formulations_13_1.png" src="_images/variational_formulations_13_1.png" />
</div>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Answer</p>
<ul class="simple">
<li><p>The solution is given by <span class="math notranslate nohighlight">\(u = (1 + \alpha)^{-1}f.\)</span></p></li>
<li><p>The results are shown below (click <code class="docutils literal notranslate"><span class="pre">+</span></code> to show the code), showing that (as expected), the result is only scaled down. This obviously reduces the noise level but also effects the amplitude of the spikes.</p></li>
</ul>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># generate spiky signal with random amplitudes</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># generate noisy signal</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># denoise</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">uhat</span> <span class="o">=</span> <span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ground truth&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">uhat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;denoised signal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_15_0.png" src="_images/variational_formulations_15_0.png" />
</div>
</div>
</div>
<div class="section" id="ell-1-denoising">
<h3><span class="section-number">5.4.6. </span><span class="math notranslate nohighlight">\(\ell_1\)</span>-denoising<a class="headerlink" href="#ell-1-denoising" title="Permalink to this headline">¶</a></h3>
<p>Repeat the previous exercise for the <span class="math notranslate nohighlight">\(\ell_1\)</span>-densoining problem</p>
<div class="math notranslate nohighlight">
\[
\min\limits_u\textstyle{\frac{1}{2}}\left\|u-f\right\|_2^2 + \alpha \left\|u\right\|_1.
\]</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Answer</p>
<p>The exact solution known as <em>soft tresholding</em>. A derivation can be found <a class="reference external" href="https://math.stackexchange.com/questions/471339/derivation-of-soft-thresholding-operator-proximal-operator-of-l-1-norm">here</a></p>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># soft tresholding operation</span>
<span class="k">def</span> <span class="nf">soft</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">alpha</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># generate spiky signal with random amplitudes</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># generate noisy signal</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># denoise</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">uhat</span> <span class="o">=</span> <span class="n">soft</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ground truth&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">uhat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;denoised signal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/variational_formulations_18_0.png" src="_images/variational_formulations_18_0.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="statistical_perspective.html" title="previous page"><span class="section-number">4. </span>A statistical perspective on inverse problems</a>
    <a class='right-next' id="next-link" href="numerical_optimisation.html" title="next page"><span class="section-number">6. </span>Numerical optimisation for inverse problems</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Tristan van Leeuwen and Christoph Brune (CC BY-NC 4.0)<br/>
        
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>